{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pleased-absolute",
   "metadata": {},
   "source": [
    "# Title: Collecting data using interactive Jupyter widgets  \n",
    "**Author details:** *Author:* Mairead Bermingham. *Contact details:* mairead.bermingham@ed.ac.uk.  \n",
    "**Notebook and data info:** This Notebook provides an example of using interactive jupyter-widgets and to collect the NHS England accident and emergency attendances and admissions (ae_attendances) data (your test data) and save it to your working ‘Data’ folder, and finally saving all the captured test data to your 'RawData'.  \n",
    "**Data:** Data consists of date, numerical data and character data from NHSRdatasets package.  \n",
    "**Copyright statement:** This Notebook is the product of The University of Edinburgh.  \n",
    "\n",
    "# Data\n",
    "The data you will be managing on the course are from the NHSRdatasets package. This package has been created to support skills development in the NHS-R community and contains several free datasets. The dataset set I have chosen to manage from the NHSRdatasets package is the NHS England accident and emergency (A&E) attendances and admissions (`ae_attendances`) data. The `ae_attendances` data includes reported attendances, four-hour breaches and admissions for all A&E departments in England for 2016/17 through 2018/19 (Apr-Mar). We previously selected a subset of the variables needed for my data capture tool, including period, attendances and breaches, and subsetted the data into test and training data. However, for this lesson, we will use the full `ae_attendances` dataset to demonstrate how to use interactive Jupyter-widgets from the *ipywidgets* package to collect all data types from the `ae_attendances` data. The R script \"./RScripts/LoadingNHSRdatasets_fulldata.R\" was used to subset the full `ae_attendances` data into test and training data.\n",
    "\n",
    "**Note**, you only need to set up widgets for the subset of the variables required for your data capture tool. We are using the full data set here, as you will be using interactive Jupyter widgets to collect different variables from your `ae_attendances` data subsets.\n",
    "\n",
    "### The *pandas* package\n",
    "To import the data, you will need to load the *pandas* package. The Python *pandas* package is used for data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frozen-attendance",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/ae_attendances_ENG_4hr_perfom_test_full.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1139/1156807654.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load the 'pandas' package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtestData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/ae_attendances_ENG_4hr_perfom_test_full.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtestData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/ae_attendances_ENG_4hr_perfom_test_full.csv'"
     ]
    }
   ],
   "source": [
    "#Load the 'pandas' package\n",
    "import pandas as pd\n",
    "testData=pd.read_csv(\"../Data/ae_attendances_ENG_4hr_perfom_test_full.csv\")\n",
    "testData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-location",
   "metadata": {},
   "source": [
    "#### Data type\n",
    "We now need to check the data type in the testData data frame. Let us use the `dtypes` function from the Python *pandas* package to query the data types in the testData. The `dtypes` function returns the data types in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-pennsylvania",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "result = testData.dtypes\n",
    "print(\"Output:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-consciousness",
   "metadata": {},
   "source": [
    "The data type object is a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-weekend",
   "metadata": {},
   "source": [
    "Now let us collect the first row of data from the test data. \n",
    "Use the `df.head()` function to see the first row in the data frame(df).\n",
    "\n",
    "##### The `head()` function\n",
    "The `head()` function lets you look at the top n rows of a data frame. By default, it shows the first five rows in a data frame. We can specify the number of rows we want to see in a data frame with the argument “n”. For example, look at the first row (n=1) of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-checkout",
   "metadata": {},
   "source": [
    "We need to set up an empty data frame in the working data folder to collect the data captured by the Juypter widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-index",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "dfTofill = pd.DataFrame({'index': [0],# Integer\n",
    "                   'period': [pd.Timestamp('20000101')], # Date\n",
    "                   'org_code': ['NA'], # String\n",
    "                   'type': ['NA'], # String\n",
    "                   'attendances': [0], # Integer\n",
    "                   'breaches': [0], # Integer\n",
    "                   'admissions': [0], # Integer\n",
    "                   'performance': [0.0], # Float\n",
    "                   'consent': [False]}) # Boolean \n",
    "\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-recruitment",
   "metadata": {},
   "source": [
    "Save the empty data frame to your working 'Data' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-envelope",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#dfTofill.to_csv('../Data/CollectedData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-comparative",
   "metadata": {},
   "source": [
    "The empty data frame is now saved to the working 'Data' folder. Now make sure to comment out the last cell (Ctrl+/), as you only need to do this once. Now let's read in the empty data frame to collect the data from the Jupyter-widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "CollectData=pd.read_csv(\"../Data/CollectedData.csv\")\n",
    "CollectData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-millennium",
   "metadata": {},
   "source": [
    "Now let us collect the first row of data from the test data. \n",
    "Use the `df.head()` function to see the first row in the data frame(df).\n",
    "\n",
    "##### The `head()` function\n",
    "The `head()` function lets you look at the top n rows of a data frame. By default, it shows the first five rows in a data frame. We can specify the number of rows we want to see in a data frame with the argument “n”. For example, look at the first row (n=1) of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-chemistry",
   "metadata": {},
   "source": [
    "# Index variable \n",
    "The first variable contains the index number, that allows us to connect the test data to the orginal data set \"../RawData/ae_attendances.csv\". We will have to use indexing to to add the index number to the 'dfTofill' file\n",
    "\n",
    "###  Indexing in Python\n",
    "Indexing in Python is a way to refer the individual items by its position. In other words, you can directly access your elements of choice. In Python, objects are “zero-indexed” meaning the position count starts at zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_number=1155 #Remember to change for each record.\n",
    "dfTofill.iloc[0,0]=index_number\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-understanding",
   "metadata": {},
   "source": [
    "# Widgets\n",
    "Widgets are interactive Python objects that have a representation in the browser. A widget is a graphical user interface element, such as a button, dropdown or textbox. Widgets can be embedded in the Notebook and provide a user-friendly interface to collect the user input and see the impact the changes have on the data/results without interacting with your code. Widgets can transform your notebooks from static documents to dynamic dashboards, ideal for showcasing your data story.\n",
    "\n",
    "To use the widget framework, you need to import the *ipywidgets* Python package. The *ipywidgets* package provides a list of widgets commonly used in web apps and dashboards like dropdown, checkbox, radio buttons, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the 'ipywidgets' package\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-medium",
   "metadata": {},
   "source": [
    "### `display()`\n",
    "\n",
    "The *IPython.display* package is used to display different objects in Jupyter. \n",
    "You can also explicitly display a widget using the `display()` function from the *IPython.display* package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the 'IPython.display' package\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-effects",
   "metadata": {},
   "source": [
    "# Consent\n",
    "Consent is a vital area for data protection compliance. Consent means giving data subjects genuine choice and control over how you process their data. If the data subject has no real choice, consent is not freely given, and it will be invalid. The [General Data Protection Regulation](https://eu01.alma.exlibrisgroup.com/leganto/public/44UOE_INST/citation/37632538310002466?auth=SAML) sets a high standard for consent and contains significantly more detail than previous data protection legislation. Consent is defined in Article 4 as: “Consent of the data subject means any freely given, specific informed and unambiguous indication of the data subject’s wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her”.\n",
    "\n",
    "Before we collect any data, we need to get consent from the end-user to process and share the data we will collect with the data capture tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-gnome",
   "metadata": {},
   "source": [
    "## Boolean widgets\n",
    "Boolean widgets are designed to display a boolean value.\n",
    "\n",
    "### Checkbox widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-justice",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "a = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='I consent for the data I have provided to be processed and shared in accordance with data protection regulations with the purpose of improving care service provision across the UK.',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-worship",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTofill.iloc[0,8]=a.value\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-arrest",
   "metadata": {},
   "source": [
    "# The period variable  \n",
    "The period variable includes the month this activity relates to, stored as a date (1st of each month).  \n",
    "\n",
    "#### Data type\n",
    "We now need to check the data type in the testData data frame. Let us use the `dtypes` function from the Python *pandas* package to query the data types in the testData. The `dtypes` function returns the data types in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[1])\n",
    "#String data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-persian",
   "metadata": {},
   "source": [
    "The data type object is a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-camcorder",
   "metadata": {},
   "source": [
    "##### The `head()` function\n",
    "The `head()` function lets you look at the top n rows of a data frame. By default, it shows the first five rows in a data frame. We can specify the number of rows we want to see in a data frame with the argument “n”. For example, look at the first row (n=1) of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-cooper",
   "metadata": {},
   "source": [
    "### DatePicker widget \n",
    "We next need to set up a DatePicker widget to collect the period data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = widgets.DatePicker(\n",
    "    description='Period',\n",
    "    disabled=False\n",
    ")\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-donor",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "dfTofill.iloc[0,1]=b.value\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-fitness",
   "metadata": {},
   "source": [
    "## The org_code variable\n",
    "The org_code variable includes the Organisation data service (ODS) code for the organisation. The ODS code is a unique code created by the Organisation data service within [NHS Digital](_https://www.digitalsocialcare.co.uk/latest-guidance/how-to-find-your-ods-code/), and used to identify organisations across health and social care. ODS codes are required in order to gain access to national systems like NHSmail and the Data Security and Protection Toolkit. If you want to know the organisation associated with a particular ODS code, you can look it up from the following address: <https://odsportal.digital.nhs.uk/Organisation/Search>. For example, the organisation associated with the ODS code 'AF003' is\n",
    "[Parkway health centre](https://odsportal.digital.nhs.uk/Organisation/OrganisationDetails?organisationId=132839&showOpenChildredOnly=True).      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-mistake",
   "metadata": {},
   "source": [
    "#### Data type\n",
    "We now need to check the data type in the testData data frame. Let us use the `dtypes` function from the Python *pandas* package to query the data types in the testData. The `dtypes` function returns the data types in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[2])\n",
    "#String data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-sheriff",
   "metadata": {},
   "source": [
    "The data type object is a string.\n",
    "\n",
    "#### Describe the test data\n",
    "Here we are going to use the `describe()` function from the *numpy* Python package to calculate summary statistics for the testData data frame. The numpy package is the core package for scientific computing in Python. The `describe()` function from the *numpy* package computes the descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-devices",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#Load the 'numpy' package\n",
    "import numpy as np\n",
    "testData.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-consciousness",
   "metadata": {},
   "source": [
    "#### Applying *pandas* `unique()` function\n",
    "We must first use the *pandas* package `unique()` function to get the unique Organisation data service (ODS) codes in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_code=list(testData['org_code'].unique())\n",
    "org_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-eclipse",
   "metadata": {},
   "source": [
    "##### The `head()` function\n",
    "The `head()` function lets you look at the top n rows of a data frame. By default, it shows the first five rows in a data frame. We can specify the number of rows we want to see in a data frame with the argument “n”. For example, look at the first row (n=1) of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-princess",
   "metadata": {},
   "source": [
    "## Selection widgets\n",
    "Several widgets can be used to display single selection lists. You can specify the selectable options by passing a list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=widgets.Select(\n",
    "    options=org_code,\n",
    "    value='C82010',\n",
    "    rows=len(org_code),\n",
    "    description='ODS code:',\n",
    "    disabled=False\n",
    ")\n",
    "display(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTofill.iloc[0,2]=c.value\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-convenience",
   "metadata": {},
   "source": [
    "## The type variable\n",
    "The type variable contains the department type for this activity, either  \n",
    "* **1:** Emergency departments are a consultant-led 24-hour service with full resuscitation facilities and designated accommodation for the reception of accident and emergency patients,  \n",
    "* **2:** Consultant-led mono speciality accident and emergency service (e.g. ophthalmology, dental) with designated accommodation for the reception of patients, or  \n",
    "* **other:** Other type of A&E/minor injury activity with designated accommodation for the reception of accident and emergency patients. The department may be doctor-led or nurse-led and treats at least minor injuries and illnesses and can be routinely accessed without an appointment. A service mainly or entirely appointment-based (for example, a GP Practice or Outpatient clinic) is excluded even though it may treat a number of patients with minor illnesses or injury. Excludes NHS walk-in centres.[(National Health Service, 2020)](https://eu01.alma.exlibrisgroup.com/leganto/public/44UOE_INST/citation/37459630310002466?auth=SAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-newman",
   "metadata": {},
   "source": [
    "#### Data type\n",
    "We now need to check the data type in the testData data frame. Let us use the `dtypes` function from the Python *pandas* package to query the data types in the testData. The `dtypes` function returns the data types in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[3])\n",
    "#String data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-optimization",
   "metadata": {},
   "source": [
    "The data type object is a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-session",
   "metadata": {},
   "source": [
    "#### Applying *pandas* `unique()` function\n",
    "We must first use the *pandas* package `unique()` function to get the unique department type in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "type=list(testData['type'].unique())\n",
    "type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-school",
   "metadata": {},
   "source": [
    "##### The `head()` function\n",
    "The `head()` function lets you look at the top n rows of a data frame. By default, it shows the first five rows in a data frame. We can specify the number of rows we want to see in a data frame with the argument “n”. For example, look at the first row (n=1) of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-reading",
   "metadata": {},
   "source": [
    "### RadioButtons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=widgets.RadioButtons(\n",
    "    options=type,\n",
    "#     value='other',\n",
    "    description='Type:',\n",
    "    disabled=False\n",
    ")\n",
    "display(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTofill.iloc[0,3]=d.value\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-correspondence",
   "metadata": {},
   "source": [
    "# The attendances variable\n",
    "The attendances variable includes the number of attendances for this department type at this organisation for this month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-wisdom",
   "metadata": {},
   "source": [
    "#### Data type\n",
    "We now need to check the data type in the testData data frame. Let us use the `dtypes` function from the Python *pandas* package to query the data types in the testData. The `dtypes` function returns the data types in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-generator",
   "metadata": {},
   "source": [
    "##### The `head()` function\n",
    "The `head()` function lets you look at the top n rows of a data frame. By default, it shows the first five rows in a data frame. We can specify the number of rows we want to see in a data frame with the argument “n”. For example, look at the first row (n=1) of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-excess",
   "metadata": {},
   "source": [
    "## Numeric widgets\n",
    "There are many widgets distributed with ipywidgets that are designed to display numeric values. Widgets exist for displaying integers and floats, both bounded and unbounded. The integer widgets share a similar naming scheme to their floating point counterparts. By replacing Float with Int in the widget name, you can find the Integer equivalent.\n",
    "\n",
    "### IntText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "e=widgets.IntText(\n",
    "    value=0,\n",
    "    description='Attendances:',\n",
    "    disabled=False)\n",
    "display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTofill.iloc[0,4]=e.value\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-cross",
   "metadata": {},
   "source": [
    "# The breaches variable\n",
    "The breaches variable includes the number of attendances that breached the four hour target.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-stephen",
   "metadata": {},
   "source": [
    "#### Data type\n",
    "We now need to check the data type in the testData data frame. Let us use the `dtypes` function from the Python *pandas* package to query the data types in the testData. The `dtypes` function returns the data types in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-female",
   "metadata": {},
   "source": [
    "### IntText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=widgets.IntText(\n",
    "    value=0,\n",
    "    description='Breaches:',\n",
    "    disabled=False)\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTofill.iloc[0,5]=f.value\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-prior",
   "metadata": {},
   "source": [
    "#### The admissions variable\n",
    "The admissions variable includes the number of attendances that resulted in an admission to the hospital.[(Chris Mainey, 2021)](https://eu01.alma.exlibrisgroup.com/leganto/public/44UOE_INST/citation/37444097490002466?auth=SAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-divide",
   "metadata": {},
   "source": [
    "#### Data type\n",
    "We now need to check the data type in the testData data frame. Let us use the `dtypes` function from the Python *pandas* package to query the data types in the testData. The `dtypes` function returns the data types in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-evaluation",
   "metadata": {},
   "source": [
    "It is an integer variable.\n",
    "\n",
    "##### The `head()` function\n",
    "The `head()` function lets you look at the top n rows of a data frame. By default, it shows the first five rows in a data frame. We can specify the number of rows we want to see in a data frame with the argument “n”. For example, look at the first row (n=1) of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-looking",
   "metadata": {},
   "source": [
    "### IntText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=widgets.IntText(\n",
    "    value=0,\n",
    "    description='Admissions:',\n",
    "    disabled=False)\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTofill.iloc[0,6]=g.value\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-hardware",
   "metadata": {},
   "source": [
    "# The performance variable\n",
    "The performance variable was calculated for the whole of England as (1 - breaches)/ attendances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-economics",
   "metadata": {},
   "source": [
    "#### Data type\n",
    "We now need to check the data type in the testData data frame. Let us use the `dtypes` function from the Python *pandas* package to query the data types in the testData. The `dtypes` function returns the data types in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-banner",
   "metadata": {},
   "source": [
    "It is a float variable.\n",
    "\n",
    "##### The `head()` function\n",
    "The `head()` function lets you look at the top n rows of a data frame. By default, it shows the first five rows in a data frame. We can specify the number of rows we want to see in a data frame with the argument “n”. For example, look at the first row (n=1) of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-uniform",
   "metadata": {},
   "source": [
    "### FloatText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=widgets.FloatText(\n",
    "    value=0.0,\n",
    "    description='Performance:',\n",
    "    disabled=False\n",
    ")\n",
    "display(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTofill.iloc[0,7]=h.value\n",
    "dfTofill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-algeria",
   "metadata": {},
   "source": [
    "# Concatenating the collected data to the CollectData data frame.   \n",
    "Let us use the `concat()` function from the Python *pandas* package to append the CollectData and dfTofill data frames. The concat() function is used to concatenate *pandas* objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CollectData is the first data frame\n",
    "# dfTofill is the second data frame\n",
    "CollectData  = pd.concat([CollectData, dfTofill])\n",
    "display(CollectData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-worship",
   "metadata": {},
   "source": [
    "## Have you consent to process and share the data before you save it to the working data folder?\n",
    "\n",
    "Before we save our data to file, we must make sure we have consent to do so. The following line of code, will ensure that you have consent to save data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "CollectData=CollectData[CollectData['consent'] == True]\n",
    "display(CollectData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-league",
   "metadata": {},
   "source": [
    "### Saving the CollectData data frame\n",
    "Saving the data collected by your data-capture tool to the working data folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "CollectData.to_csv('../Data/CollectedData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-basic",
   "metadata": {},
   "source": [
    "That is the CollectData data frame saved to the working 'Data' folder. You need to iterate through this Notebook until you have collected all of your test data and then save the captured test data to your 'RawData' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CollectData.to_csv('../RawData/CollectedDataFinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-swift",
   "metadata": {},
   "source": [
    "That is the final CollectData data frame saved to the 'RawData' folder. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# The user interface for your data collection tool \n",
    "\n",
    "In this section you will provide a little backgrown for your end user, why your need ther data, and what you are going to do with it.\n",
    "\n",
    "## The Flexbox layout\n",
    "\n",
    "\n",
    "The Box widget enables rich reactive layouts in the Jupyter notebook. It aims at providing an efficient way to lay out, align and distribute space among your widgets in a box. The HBox (Horisontal layout) and VBox (vericallayout) classes above are special cases of the Box widget.\n",
    "\n",
    "Again, the whole flexbox spec is exposed via the layout attribute of the container widget (Box) and the contained items. One may share the same layout attribute among all the contained items.\n",
    "\n",
    "flex-flow is a shorthand for the flex-direction \n",
    "flex defines the ability for a flex item to grow or shrnk if necessary to fill the space. \n",
    "\n",
    "\n",
    "### Create reactive form for end-user\n",
    "Lets uste the VBox widget to a reactive form for our enduser.\n",
    "The form itself, and each row in the form is a Box widget.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#form=widgets.VBox([a,b,c,d,e,f,g,h])\n",
    "form=widgets.VBox([a,b,e,f])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-monthly",
   "metadata": {},
   "source": [
    "# Our commitment to a maximum four-hour accident and emergency wait \n",
    "\n",
    "\n",
    "The four-hour accident and emergency waiting time target is a pledge set out in our ['Handbook to the NHS Constitution'](https://eu01.alma.exlibrisgroup.com/leganto/public/44UOE_INST/citation/37819402820002466?auth=SAML). \n",
    "Our operational standard is that at least 95% of patients attending A&E should be admitted, transferred, or discharged within four hours.[(The UK Government, 2022)](https://eu01.alma.exlibrisgroup.com/leganto/public/44UOE_INST/citation/37819402820002466?auth=SAML)\n",
    "\n",
    "Since 2007, the national standard for A&E is that new and unplanned return attendances at an A&E service should be seen and then admitted, transferred or discharged within four hours. This standard applies to all areas of emergency care, including attendances in trolleyed areas of an Assessment Unit as well as Emergency Departments and minor injury units. For service users that require admission to A&E, the time they wait between the doctor deciding that they should be admitted for treatment and the patient arriving on the ward is an important measure of safety. The Royal College of Emergency Medicine estimated that overcrowding and extreme delays led to 4,519 excess deaths in England in 2020/21.  In March 2022, 136,297 patients waited over four hours from decision to admission, 27% of all patients. [(The Nuffield Trust, 2022)](https://eu01.alma.exlibrisgroup.com/leganto/public/44UOE_INST/citation/37819506800002466?auth=SAML)\n",
    "\n",
    "To keep our service users and NHS England safe by ensuring A&E departments provide the fastest and most appropriate care for service users as and when they need it. We need your monthly data on the number of attendances and breaches over time to make an available to your and other service managers to set as a benchmark against which to assess and improve your department’s performance against the 4-hour standard. We would be very grateful if you could could take one minute each month to share your data with us in the form below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-shelter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-avatar",
   "metadata": {},
   "source": [
    "Thank you for sharing your data, and giving us your consent to process and share it with other service management teams across England. We will add your data to our [open data resource](https://github.com/B111333/B111333WorkingWithDataTypesAndStructuresInPythonandR_Assessment) for you to use now or in the futures as a benchmark against which to assess and improve your department’s performance against the 4-hour standard. \n",
    "\n",
    "\n",
    "I hope these examples help you to improve your Python programming skills. Happy Coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
